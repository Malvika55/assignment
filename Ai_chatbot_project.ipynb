{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSRhT4yzockXRQEW4z2+jk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Malvika55/assignment/blob/main/Ai_chatbot_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2mfft6clD2Fr"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import random\n",
        "import string\n",
        "import warnings\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0k4FqUFEJmO",
        "outputId": "07a79c20-70b9-4af0-9f0c-3c82f3179a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import WordNetLemmatizer\n",
        "nltk.download('popular', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True) # Added explicit download for punkt_tab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp0K0YdLEYTc",
        "outputId": "df8fa546-fd60-4590-84df-06babe045ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "file_name = 'chatbot.txt'\n",
        "if not os.path.exists(file_name):\n",
        "    # Create a dummy file if it doesn't exist for demonstration\n",
        "    with open(file_name, 'w') as f_dummy:\n",
        "        f_dummy.write(\"This is a dummy text file for chatbot. Hello World.\")\n",
        "    print(f\"'{file_name}' not found. A dummy file has been created for demonstration purposes.\")\n",
        "\n",
        "f=open(file_name,'r',errors = 'ignore')\n",
        "raw=f.read()\n",
        "raw = raw.lower()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ix-y0P2pEjrN",
        "outputId": "b7a69232-7e4a-4097-a6e1-fca838b622b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'chatbot.txt' not found. A dummy file has been created for demonstration purposes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokens = nltk.sent_tokenize(raw)\n",
        "word_tokens = nltk.word_tokenize(raw)"
      ],
      "metadata": {
        "id": "hu0sfIJsFo4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "    return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def LemNormalize(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "4XHFA_m8Gczp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GREETING_INPUTS =(\"hello\",\"hi\",\"greetings\",\"sup\",\"what's up\",\"hey\")\n",
        "GREETING_RESPONSES =(\"hi\",\"hey\",\"*nods*\",\"hi there\",\"hello\",\"I am glad! You are talking to me\", \"how can I help you?\", \"good to see you again!\", \"Hello there!\", \"Nice to meet you!\", \"What can I do for you?\")\n",
        "def greeting(sentence):\n",
        "    for word in sentence.split():\n",
        "        if word.lower() in GREETING_INPUTS:\n",
        "            return random.choice(GREETING_RESPONSES)"
      ],
      "metadata": {
        "id": "x4IVgOLZGo6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def response(user_response):\n",
        "    robo_response=''\n",
        "    sent_tokens.append(user_response)\n",
        "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
        "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "    idx=vals.argsort()[0][-2]\n",
        "    flat = vals.flatten()\n",
        "    flat.sort()\n",
        "    req_tfidf = flat[-2]\n",
        "    if(req_tfidf==0):\n",
        "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sent_tokens[idx]\n",
        "        return robo_response\n",
        "\n"
      ],
      "metadata": {
        "id": "_z_NXb4kPW3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ROBO : My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "flag = True # Initialize the flag variable\n",
        "while(flag==True):\n",
        "    user_response = input()\n",
        "    user_response=user_response.lower()\n",
        "    if(user_response!='bye'):\n",
        "        if(user_response=='thanks' or user_response=='thank you'):\n",
        "            flag=False\n",
        "            print(\"ROBO : You are welcome..\")\n",
        "        else:\n",
        "            if(greeting(user_response)!=None):\n",
        "                print(\"ROBO : \"+greeting(user_response))\n",
        "            else:\n",
        "                print(\"ROBO : \",end=\"\")\n",
        "                print(response(user_response))\n",
        "                sent_tokens.remove(user_response)\n",
        "    else:\n",
        "        flag=False\n",
        "        print(\"ROBO : Bye! take care..\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfHOwbuOQGRo",
        "outputId": "19286b5b-6bb4-421d-bc9f-b247142d14ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROBO : My name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
            "hi\n",
            "ROBO : good to see you again!\n",
            "help\n",
            "ROBO : I am sorry! I don't understand you\n",
            "bye\n",
            "ROBO : Bye! take care..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Warming Chatbot2**"
      ],
      "metadata": {
        "id": "wNlqfYfJRp9l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "\n"
      ],
      "metadata": {
        "id": "PhTQ1vIWRvb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scrappimg article from wiki page\n",
        "\n",
        "import urllib.request\n",
        "import bs4 as bs\n",
        "\n",
        "# Add a User-Agent header to mimic a web browser\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "\n",
        "# Create a Request object with the URL and headers\n",
        "req = urllib.request.Request('https://en.wikipedia.org/wiki/Global_warming', headers=headers)\n",
        "rawdata = urllib.request.urlopen(req)\n",
        "\n",
        "article = rawdata.read()\n",
        "\n",
        "html_data = bs.BeautifulSoup(article, 'html.parser')\n",
        "all_paragraphs = html_data.find_all('p')\n",
        "\n",
        "article_text = \"\"\n",
        "for p in all_paragraphs:\n",
        "    article_text += p.text\n",
        "\n",
        "article_text = article_text.lower()"
      ],
      "metadata": {
        "id": "xQ_QyADPSHrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
        "article_text = re.sub(r'\\s+', ' ', article_text)"
      ],
      "metadata": {
        "id": "v3Sfj8xlTaHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_list = nltk.sent_tokenize(article_text)\n",
        "article_words= nltk.word_tokenize(article_text)"
      ],
      "metadata": {
        "id": "z0j2EgwGTYpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "def LemTokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "def RemovePuncatioms(text):\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ],
      "metadata": {
        "id": "mq5_r0krTliF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "greeting_inputs = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
        "greeting_responses = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
        "def reply_greeting(text):\n",
        "    for word in text.split():\n",
        "        if word.lower() in greeting_inputs:\n",
        "            return random.choice(greeting_responses)"
      ],
      "metadata": {
        "id": "mB45mwsxTmCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "EB2lGZReTmGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def give_reply(user_input):\n",
        "    robo_response=''\n",
        "    sentence_list.append(user_input)\n",
        "    word_vectors = TfidfVectorizer(tokenizer=RemovePuncatioms, stop_words='english')\n",
        "    vectorized_words = word_vectors.fit_transform(sentence_list)\n",
        "    similarity_values = cosine_similarity(vectorized_words[-1], vectorized_words)\n",
        "    similar_sentence_number = similarity_values.argsort()[0][-2]\n",
        "    similar_vector_values = similarity_values.flatten()\n",
        "    similar_vector_values.sort()\n",
        "    matched_vector = similar_vector_values[-2]\n",
        "    if(matched_vector==0):\n",
        "        robo_response = robo_response+\"I am sorry! I could not understand you\"\n",
        "        return robo_response\n",
        "    else:\n",
        "        robo_response = robo_response+sentence_list[similar_sentence_number]\n",
        "        return robo_response"
      ],
      "metadata": {
        "id": "EviLoQP7UV0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continue_discussion = True\n",
        "print(\"Hello my name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
        "while(continue_discussion == True):\n",
        "    user_input = input()\n",
        "    user_input = user_input.lower()\n",
        "    if(user_input != 'bye'):\n",
        "        if(user_input == 'thanks' or user_input == 'thank you'):\n",
        "            continue_discussion = False\n",
        "            print(\"You are welcome..\")\n",
        "\n",
        "\n",
        "        else:\n",
        "            if(reply_greeting(user_input) != None):\n",
        "                print(\"ROBO : \"+reply_greeting(user_input))\n",
        "            else:\n",
        "                print(\"ROBO : \", end=\"\")\n",
        "                print(give_reply(user_input))\n",
        "                sentence_list.remove(user_input)\n",
        "    else:\n",
        "        continue_discussion = False\n",
        "        print(\"ROBO : Bye! take care..\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50FdlDuXUV3e",
        "outputId": "55c822d8-b4e4-4f57-d66b-7ec23ab8faa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello my name is Robo. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
            "hi\n",
            "ROBO : I am glad! You are talking to me\n",
            "hot\n",
            "ROBO : with worst-case climate change, models project that areas almost one-third of humanity live in might become sahara-like uninhabitable and extremely hot climates.\n",
            "cold\n",
            "ROBO : this is why the temperature change is defined in terms of a 20-year average, which reduces the noise of hot and cold years and decadal climate patterns, and detects the long-term signal.\n",
            "winter\n",
            "ROBO : farmers can promote sequestration of carbon in soils through practices such as use of winter cover crops, reducing the intensity and frequency of tillage, and using compost and manure as soil amendments.\n",
            "rainy\n",
            "ROBO : I am sorry! I could not understand you\n",
            "rain\n",
            "ROBO : sulfur dioxide causes acid rain, but it also produces sulfate aerosols in the atmosphere, which reflect sunlight and cause global dimming.\n",
            "bye\n",
            "ROBO : Bye! take care..\n"
          ]
        }
      ]
    }
  ]
}